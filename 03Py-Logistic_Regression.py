# -*- coding: utf-8 -*-
"""3-logistic-regression.ipynb

Automatically generated by Colaboratory.

# Image Classification with Logistic Regression
"""

# importing libraries
import torch
import torchvision    # pytorch for computer vision 
from torchvision.datasets import MNIST

# to delete output in google colab
from google.colab import output

# download training data
data = MNIST(root = 'data/', 
             download = True)
output.clear()

# amount of data
len(data)

# get test data 
test = MNIST(root = 'data/',
             train = False)
len(test)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

img, label = data[0]
plt.imshow(img, cmap='gray')
print('Label:', label)

"""We are going to change data to tensor variables."""

import torchvision.transforms as transforms

# download data
data = MNIST(root = 'data/',
             train = True,
             transform = transforms.ToTensor())

# split to images and labels
img, label = data[0]
print(img.shape, label)

# select a region of image and get max and min
print(img[:, 10:15, 10:15])
print(torch.max(img), torch.min(img))

"""Where 0 is black color and 1 is white color."""

plt.imshow(img[0,10:15,10:15], 'gray')
plt.show()

"""## **Training and Validation**



1.   **Training set:** compute the loss and adjust the weights of the model using gradient descent.
2.   **Validation set:** adjust hyperparameters (for example: lr) and pick the best version of the model.
3. **Test set:** used to compare different models or types of modelling approaches and report the final accuracy of the model.


"""

import numpy as np

def split_indices(n, val_pct):
  """
      args:
              n -  number of values       (int)
              val_pct - percent to take   (float)
      return: 
              training set      (array of indices) 
              validation  set   (array of indices)
  """
  # determine size of validation set
  n_val = int(val_pct * n)

  # create random permutation of 0 to n-1
  idxs = np.random.permutation(n)

  # pick first n_val indices for validation set
  return idxs[n_val:], idxs[:n_val]

train_i, val_i = split_indices(n = len(data),
                               val_pct = 0.2)

print(len(train_i), len(val_i))
print('Sample val indices:', val_i[:10])

from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data.dataloader import DataLoader

batch_size = 100

# training sampler and data loader
train_sampler = SubsetRandomSampler(train_i)
train_loader = DataLoader(data,
                          batch_size,
                          sampler=train_sampler)

# validation sampler and data loader
val_sampler = SubsetRandomSampler(val_i)
val_loader = DataLoader(data,
                          batch_size,
                          sampler=val_sampler)

"""## **Model**



*   **Logistic regression** is almost identical to linear regression model `( pred = x @ w.t() + b )`
*   We just use `nn.Linear` to create the model instead of defining and initializing the matrices manually.
*   The output is a vector of sie 10, with every probability of particular target label (0-9). 


 
"""

import torch.nn as nn

input_size = 28 * 28
num_classes = 10

# logistic regression model
model = nn.Linear(input_size, num_classes)

print(model.weight.shape)
model.weight

print(model.bias.shape)
model.bias

for images, labels in train_loader:
  print(labels)
  print(images.shape)
  outputs = model(images)
  break

"""This error y because we have a shape 1x20x20 but we need a vector of size 784."""

class MnistModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.linear = nn.Linear(input_size, num_classes)

  def forward(self, xb):
    xb = xb.reshape(-1, 784)
    out = self.linear(xb)
    return out

model = MnistModel()



